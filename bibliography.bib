@misc{bernstein2005cache,
  title={Cache-timing attacks on AES},
  author={Bernstein, Daniel J},
  year={2005}
}

@incollection{bonneau2006cache,
  title={Cache-collision timing attacks against AES},
  author={Bonneau, Joseph and Mironov, Ilya},
  booktitle={Cryptographic Hardware and Embedded Systems-CHES 2006},
  pages={201--215},
  year={2006},
  publisher={Springer}
}

@inproceedings{gullasch2011cache,
  title={Cache games--{Bringing} access-based cache attacks on {AES} to practice},
  author={Gullasch, David and Bangerter, Endre and Krenn, Stephan},
  booktitle={Security and Privacy (SP), 2011 IEEE Symposium on},
  pages={490--505},
  year={2011},
  organization={IEEE},
  annote={
    \setlength{\parskip}{1.5ex}
    Describes an access-driven full-key recovery cache attack on AES.
    The authors claim it is the first attack to work in Ostvik's~\cite{osvik2006cache} \textit{asynchronous}
      model --- the online attack phase requires only co-location on the same CPU core and shared memory, but no
      explicit interactions.
    It also requires no knowledge of the plaintexts or even the ciphertexts, works against compressed-table
      implementations for the first time, and can recover a full AES-128 key after observing just \num{100}~encryptions
      (\num{2.8}~seconds) and a three-minute offline analysis phase.
    \par
    The cryptanalysis uses a novel attack against the Completely Fair Scheduler (CFS), the scheduler used in the Linux
      kernel, ``to observe (on average) every single memory access of the victim process.''
    The CFS attack runs one hundred threads which spend most of their time in the ``blocked'' state, ensuring that
      their total execution time is low and CFS will prioritize them over the victim process when they are unblocked.
    When an attack thread wakes, it reads the memory accesses of the process that ran just before, then sets a timer to
      wake up the next attack thread, after a short delay, then yields the CPU so that the victim process can run.
    The goal is to unblock the next attack thread after exactly one memory access by the victim process. In the
      authors' case, this was about \num{1500}~CPU cycles.
    They computed the required delay empirically, using OS-specific techniques; they also used two artificial neural
      networks, trained on about \num{168000}~encryptions using the same OS, hardware, and encryption library as the
      target, to design noise-reduction algorithms for this step to filter out irrelevant memory accesses.
    \par
    Because of the reliance on specific operating system properties for accurate measurement, the attack is highly
      dependent on the target platform~--- the authors mentioned that any deviation from their Linux kernel running
      OpenSSL~0.9.8n on a single-core x86 CPU required significant adjustment.
    OpenSSL~1.0 makes the attack significantly more difficult.
    They mentioned that even ``minor updates to the operating system'' required the attack to be re-tuned.
    \par
    They suggest that porting the attack to target other operating systems would be difficult, especially against
      proprietary operating systems where the attacker would have to reverse-engineer the scheduler.
    Multi-core CPUs also present a challenge, because the cache access attack depends on the victim process being
      preempted while the spy process is running.
    They suggest that the spy could run on multiple cores, and also try to influence the target to run on certain cores
      by exploiting the task scheduler or making specific system calls.
  }
}

@inproceedings{osvik2006cache,
  title={Cache attacks and countermeasures: the case of {AES}},
  author={Osvik, D. A. and Shamir, A. and Tromer, E.},
  booktitle={RSA Conference Cryptographers Track (CT-RSA) 2006},
  year={2006}
}

@inproceedings{tromer2009cache,
  title={Efficient cache attacks on {AES}, and countermeasures},
  author={Tromer, E. and Osvik, D. A. and Shamir, A.},
  booktitle={Journal of Cryptology},
  year={2009},
}

@incollection{ristenpart2009cloud,
  title={Hey, you, get off of my cloud: exploring information leakage in third-party compute clouds},
  author={Ristenpart, Thomas and Tromer, Eran and Shacham, Hovav and Savage, Stefan},
  booktitle={CCS '09 Proceedings of the 16th ACM conference on Computer and communications security},
  pages={199--212},
  year={2009},
  publisher={ACM},
  annote={
    \setlength{\parskip}{1.5ex}
    Describes a method for achieving co-residence with target VMs on the cloud and exploiting information leakage
      between these VMs using Amazon's EC2 service as an example.
    The attack takes advantage of the fact that many VMs can be created by the same user, and that there is a
      possibility that these might run on the same hardware as a target due to the way the VMs share physical
      resources.
    Once co-location is achieved, an attacker can use side-channels (namely caches) to get information about the other
      instances running on the same machine as the malicious VM.  
    \par
    A 'map' of the EC2 service was constructed in order to improve the likelihood of placing a VM on the same host as
      the target.
    By creating multiple instances for each permutation of the creation parameters, the authors observed a trend
      between internal IP addresses and creation parameters.
    These internal IP addresses were concluded to be statically associated with physical machines.
    Use of the created map requires translating the external IP of the target to an internal IP, which is made possible
      by the DNS service provided by EC2.
      This allows an attacker to determine the creation parameters of a target instance with a fairly high degree of
      accuracy using only its IP address. 
    \par
    There are multiple ways to check if two instances are co-resident.
    Each physical machine has a privileged VM associated with it called Domain0, or Dom0.
    Two VMs which are co-located will have identical Dom0 IP addresses and internal IP addresses which are numerically
      close.
    Measuring the round-trip time for a packet sent between the two VMs can also be used to tell if they are
      co-resident, as it is significantly lower in co-resident instances.
    The Dom0 IP check was used for all subsequent co-location testing as experiments showed that it produced no false
      positives.
    \par
    Two strategies were used to prove that achieving co-residence was possible.
    The first used a brute-force technique by creating a large number of probe instances and targeting a large number
      of potential victims.
    The probes checked if they were co-resident with any of the target VMs, then were immediately deactivated if they
      were not.
    This method achieved a reasonable success rate, covering 8.4\% of the targets.
    A second method monitored a victim server, waiting for it to disappear when not needed, then reappear as a new
      instance.
    The attacker then ran many instances using the same creation parameters as the target.
    Experiments with the placement of new instances found parallel placement locality (instances launched at around the
      same time tend to be placed on the same hardware).
    This, along with the 'map' created earlier, led to a much more successful approach, achieving co-residence 40\% of
      the time.
    \par
    Finally, the authors describe attacks which can be carried out on a co-resident VM.
    Most of these attacks take advantage of the \name{Prime+Probe} technique~\cite{osvik2006cache, tromer2009cache}
      to measure the load on a given machine.
    By measuring cache usage, an attacker can determine co-location without using the techniques described earlier.
    Cache usage can also be used to estimate traffic to a web server or measure the length of time between keystrokes
      for the purpose of recovering a password.
  }
}
  
@incollection{irazoqui2014wait,
  title={Wait a minute! A fast, {Cross-VM} attack on {AES}},
  author={Irazoqui, Gorka and Inci, Mehmet Sinan and Eisenbarth, Thomas and Sunar, Berk},
  booktitle={Research in Attacks, Intrusions and Defenses},
  pages={299--319},
  year={2014},
  publisher={Springer},
  annote={
    Demonstrates a practical, fast, and realistic full key recovery against AES across virtual machines.
    The attack is based on the \name{Flush+Reload} attack from Gullasch \latin{et al.} \cite{gullasch2011cache}.
    It works against any T-table based cipher implementation, but only when the VMs are using same sort of memory
      sharing mechanism such as VMware TPS.
    Key recovery takes about one minute (400,000~encryptions) in a realistic cross-VM setting.
    \par
    The attack assumes the use of the co-location technique invented by Ristenpart \latin{et al.} to move to the same
      host as the target VM.
    Once co-located, it uses a \name{Flush+Reload} attack, which works in three steps:
    \begin{enumerate}
      \item \emph{flush} the cache lines which the attacker wants to observe
      \item wait for the target to run the interesting fragment of code such as an encryption
      \item \emph{reload} the same memory lines; the cache lines which the target accessed will be cached, and will
        load faster for the attacker.
    \end{enumerate}
    \par
    Specifically, the \name{Flush+Reload} targets accesses of the T table used in the final round of encryption.
    By observing accesses of the final T table, the attacker is able to observe the final-round state of the algorithm
      and can use this information, together with the ciphertext, to recover the key.
    \par
    The attack takes advantage of two isolation leaks which the target system relies on to improve performance: The
      fact that identical memory pages (such as libraries) are usually shared between virtual machines, and the fact
      that L3 cache is usually shared between cores.
    The first property allows the attacker to observe the target's memory access across VMs, the second allows the
      attacker to observe memory access across CPU cores.
    As a result, the attacker and target need only be sharing the same physical host.
    \par
    Irazoqui \latin{et al.} tested their implementation on a consumer VM running VMware ESXi. The target was an
      encryption server which accepted plaintexts and responded with ciphertexts.
    The attack program ran on a different VM on a different core of the same host and was able to send encryption
      requests to the target.
    It recovered the full key in 400,000 encryptions --- less than a minute.
    They also tested their approach and observed even better results in some non cross-VM situations.
  }
}

@article{irazoquistealing,
  title={Stealing Information From Large Caches via Huge Pages},
  author={Irazoqui, Gorka and Eisenbarth, Thomas and Sunar, Berk}
}

@inproceedings{varadarajan2014scheduler,
  title={Scheduler-based defenses against cross-vm side-channels},
  author={Varadarajan, Venkatanathan and Ristenpart, Thomas and Swift, Michael},
  booktitle={Usenix Security},
  year={2014}
}

@article{yarom2013flush+,
  title={Flush+ Reload: a High Resolution, Low Noise, L3 Cache Side-Channel Attack.},
  author={Yarom, Yuval and Falkner, Katrina E},
  journal={IACR Cryptology ePrint Archive},
  volume={2013},
  pages={448},
  year={2013}
}

@inproceedings{zhang2014cross,
  title={Cross-Tenant Side-Channel Attacks in PaaS Clouds},
  author={Zhang, Yinqian and Juels, Ari and Reiter, Michael K and Ristenpart, Thomas},
  booktitle={Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security},
  pages={990--1003},
  year={2014},
  organization={ACM}
}

